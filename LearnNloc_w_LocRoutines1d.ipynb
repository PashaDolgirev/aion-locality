{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60332927",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import numpy as np\n",
    "import math, os, time, copy\n",
    "import torch.fft as tfft\n",
    "import pandas as pd\n",
    "import torch_dct as dct\n",
    "from numpy import size\n",
    "from ewaldnn1d import *\n",
    "\n",
    "torch.random.manual_seed(1234) # for reproducibility\n",
    "\n",
    "# Global settings\n",
    "dtype = torch.float64\n",
    "device = \"cpu\"\n",
    "\n",
    "data_regime = \"rough\" # \"smooth\" or \"rough\"\n",
    "\n",
    "N_grid = 512 # number of grid points\n",
    "if data_regime == \"smooth\":\n",
    "    M_cutoff = 50 # maximum harmonic\n",
    "    m = torch.arange(1, M_cutoff+1, dtype=dtype, device=device)             # (M,)\n",
    "    x = torch.linspace(0, 1, N_grid, dtype=dtype, device=device)            # (N,)\n",
    "    #design matrix needed to sample densities\n",
    "    DesignMatrix = torch.cos(torch.pi * torch.outer(m, x))                  # (M, N)\n",
    "    DerDM = -torch.pi * m[:, None] * torch.sin(torch.pi * torch.outer(m, x))  # (M, N) # derivative of design matrix\n",
    "    std_harm = 2.0 / (1.0 + 0.2 * m)**2 # std_harm = 2.0 / (1.0 + m)**2\n",
    "elif data_regime == \"rough\":\n",
    "    M_cutoff = N_grid - 1 # maximum harmonic\n",
    "    m = torch.arange(1, M_cutoff+1, dtype=dtype, device=device)             # (M,)\n",
    "    x = torch.linspace(0, 1, N_grid, dtype=dtype, device=device)            # (N,)\n",
    "    #design matrix needed to sample densities\n",
    "    DesignMatrix = torch.cos(torch.pi * torch.outer(m, x))                  # (M, N)\n",
    "    DerDM = -torch.pi * m[:, None] * torch.sin(torch.pi * torch.outer(m, x))  # (M, N) # derivative of design matrix\n",
    "    std_harm = 2.0 / (1.0 + 0.0 * m)**2\n",
    "else:\n",
    "    raise ValueError(\"regime must be 'smooth' or 'rough'\")\n",
    "\n",
    "N_train = 1500\n",
    "N_test = 250\n",
    "N_val = 250\n",
    "\n",
    "N_batch = 50\n",
    "N_epochs = 10000\n",
    "lr = 1e-2 # we will use a LR scheduler, so this is just an initial value\n",
    "min_delta = 1e-5 # min change in the monitored quantity to qualify as an improvement\n",
    "patience = 30    # epochs to wait for improvement before stopping training'\n",
    "pad_mode = \"reflect\" # padding mode for convolution-based routines: either \"zero\" or \"reflect\"\n",
    "N_feat = 1 # number of local features per grid point\n",
    "\n",
    "# interaction kernel parameters\n",
    "kernel_regime = \"exp\"  # \"power\", \"yukawa\", or \"exp\", or \"custom\"\n",
    "\n",
    "lam = 10.0\n",
    "alpha = 1.0\n",
    "xi = 5.0\n",
    "amp_Gaussian_1 = -1.0 # amplitude of first Gaussian kernel for interaction energy\n",
    "sigma_Gaussian_1 = 3.0 # width of first Gaussian kernel for interaction energy\n",
    "amp_Gaussian_2 = 2.0 # amplitude of second Gaussian kernel for interaction energy\n",
    "sigma_Gaussian_2 = 1.0 # width of second Gaussian kernel for interaction energy\n",
    "\n",
    "if kernel_regime == \"power\":\n",
    "    def E_tot(rho: torch.Tensor) -> torch.Tensor:\n",
    "        return E_int_dct(rho, kernel=\"power\", alpha=alpha)\n",
    "elif kernel_regime == \"yukawa\": \n",
    "    def E_tot(rho: torch.Tensor) -> torch.Tensor:\n",
    "        return E_int_dct(rho, kernel=\"yukawa\", lam=lam)\n",
    "elif kernel_regime == \"exp\":\n",
    "    def E_tot(rho: torch.Tensor) -> torch.Tensor:\n",
    "        return E_int_dct(rho, kernel=\"exp\", xi=xi)\n",
    "elif kernel_regime == \"custom\":\n",
    "    def E_tot(rho: torch.Tensor) -> torch.Tensor:\n",
    "        return E_int_dct(rho, kernel=\"exp\", xi=xi) + \\\n",
    "                amp_Gaussian_1 * E_int_conv(rho, kernel=\"gaussian\", sigma=sigma_Gaussian_1, pad_mode=pad_mode) + \\\n",
    "                amp_Gaussian_2 * E_int_conv(rho, kernel=\"gaussian\", sigma=sigma_Gaussian_2, pad_mode=pad_mode)\n",
    "    \n",
    "R = 20 \n",
    "r_grid = torch.arange(-R, R+1)\n",
    "plt.figure(figsize=(6,4))\n",
    "if kernel_regime == \"yukawa\":\n",
    "    plt.plot(r_grid, K_yukawa(r_grid, lam=lam), 'o-', linewidth=2) \n",
    "elif kernel_regime == \"power\":\n",
    "    plt.plot(r_grid, K_power(r_grid, alpha=alpha), 'o-', linewidth=2) \n",
    "elif kernel_regime == \"exp\":\n",
    "    plt.plot(r_grid, K_exp(r_grid, xi=xi), 'o-', linewidth=2)\n",
    "elif kernel_regime == \"custom\":\n",
    "    K_r = K_exp(r_grid, xi=xi) + \\\n",
    "          amp_Gaussian_1 * K_gaussian(r_grid, sigma=sigma_Gaussian_1) + \\\n",
    "          amp_Gaussian_2 * K_gaussian(r_grid, sigma=sigma_Gaussian_2)\n",
    "    plt.plot(r_grid, K_r, 'o-', linewidth=2)\n",
    "plt.axhline(0, color='k', linewidth=0.5)\n",
    "plt.xlabel(\"r = i - j\")\n",
    "plt.ylabel(\"K_r\")\n",
    "plt.xlim(-R, R)\n",
    "# plt.ylim((0.0, 1.0))\n",
    "plt.title(f\"Real space kernel\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# generate train/test split\n",
    "rho_train, d_rho_train, a_train = sample_density_batch(N_train, std_harm=std_harm, DesignMatrix=DesignMatrix, DerDM=DerDM)  # (N_train, N_grid)\n",
    "rho_test, d_rho_test, a_test = sample_density_batch(N_test, std_harm=std_harm, DesignMatrix=DesignMatrix, DerDM=DerDM)   # (N_test, N_grid)\n",
    "rho_val, d_rho_val, a_val = sample_density_batch(N_val, std_harm=std_harm, DesignMatrix=DesignMatrix, DerDM=DerDM)    # (N_val, N_grid)\n",
    "features_train = generate_loc_features_rs(rho_train, N_feat=N_feat)  # (N_train, N_grid, N_feat)\n",
    "features_test  = generate_loc_features_rs(rho_test, N_feat=N_feat)   # (N_test, N_grid, N_feat)\n",
    "features_val   = generate_loc_features_rs(rho_val, N_feat=N_feat)    # (N_val, N_grid, N_feat)\n",
    "\n",
    "targets_train = E_tot(rho_train)            # (N_train,)\n",
    "targets_test  = E_tot(rho_test)             # (N_test,)\n",
    "targets_val   = E_tot(rho_val)              # (N_val,)\n",
    "\n",
    "# Normalize features\n",
    "mean_feat, std_feat = compute_normalization_stats(features_train)\n",
    "features_train_norm = normalize_features(features_train, mean_feat, std_feat)\n",
    "features_test_norm = normalize_features(features_test, mean_feat, std_feat)\n",
    "features_val_norm = normalize_features(features_val, mean_feat, std_feat)\n",
    "\n",
    "# Normalize targets\n",
    "E_mean = targets_train.mean()\n",
    "E_std = targets_train.std()\n",
    "targets_train_norm = (targets_train - E_mean) / E_std\n",
    "targets_test_norm = (targets_test - E_mean) / E_std\n",
    "targets_val_norm = (targets_val - E_mean) / E_std\n",
    "\n",
    "# Datasets\n",
    "train_dataset = TensorDataset(features_train_norm, targets_train_norm)\n",
    "val_dataset   = TensorDataset(features_val_norm,   targets_val_norm)\n",
    "test_dataset  = TensorDataset(features_test_norm,  targets_test_norm)\n",
    "\n",
    "# Loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=N_batch, shuffle=True,  drop_last=False)\n",
    "val_loader   = DataLoader(val_dataset,   batch_size=N_batch, shuffle=False, drop_last=False)\n",
    "test_loader  = DataLoader(test_dataset,  batch_size=N_batch, shuffle=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49272c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_dir = \"LearningNonLocalKernel_wLocConv_checkpoints\"\n",
    "flag_train = False  # set to True to train models\n",
    "\n",
    "R_list = list(range(1, 31))\n",
    "\n",
    "if flag_train:\n",
    "    for R in R_list:\n",
    "\n",
    "        if kernel_regime == \"exp\":\n",
    "            run_name = f\"loc_window_kernel_{R}_\" + data_regime + '_' + kernel_regime + f\"_xi{xi}\"\n",
    "        elif kernel_regime == \"yukawa\":\n",
    "            run_name = f\"loc_window_kernel_{R}_\" + data_regime + '_' + kernel_regime + f\"_lam{lam}\"\n",
    "        elif kernel_regime == \"power\":\n",
    "            run_name = f\"loc_window_kernel_{R}_\" + data_regime + '_' + kernel_regime + f\"_alpha{alpha}\"\n",
    "\n",
    "        torch.manual_seed(1234) # for reproducibility\n",
    "\n",
    "        model = KernelOnlyEnergyNN(\n",
    "            R=R,\n",
    "            pad_mode=pad_mode,\n",
    "            mean_feat=mean_feat,\n",
    "            std_feat=std_feat,\n",
    "            E_mean=E_mean,\n",
    "            E_std=E_std,\n",
    "        ).to(device)\n",
    "        \n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "        criterion = nn.MSELoss()\n",
    "\n",
    "        # Reduce LR when val loss plateaus\n",
    "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer, mode='min', factor=0.5, patience=patience, cooldown=2, min_lr=1e-6\n",
    "        )\n",
    "\n",
    "        hist, best_epoch = train_with_early_stopping(\n",
    "            model=model,\n",
    "            train_loader=train_loader,\n",
    "            val_loader=val_loader,\n",
    "            criterion=criterion,\n",
    "            optimizer=optimizer,\n",
    "            scheduler=scheduler,\n",
    "            max_epochs=N_epochs,\n",
    "            patience=patience,\n",
    "            min_delta=min_delta,\n",
    "            ckpt_dir=ckpt_dir,\n",
    "            run_name=run_name,\n",
    "            learning_regime=\"window\",\n",
    "            N_grid=N_grid,\n",
    "            device=device,\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72b6ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "R = 30\n",
    "\n",
    "if kernel_regime == \"exp\":\n",
    "    run_name = f\"loc_window_kernel_{R}_\" + data_regime + '_' + kernel_regime + f\"_xi{xi}\"\n",
    "elif kernel_regime == \"yukawa\":\n",
    "    run_name = f\"loc_window_kernel_{R}_\" + data_regime + '_' + kernel_regime + f\"_lam{lam}\"\n",
    "elif kernel_regime == \"power\":\n",
    "    run_name = f\"loc_window_kernel_{R}_\" + data_regime + '_' + kernel_regime + f\"_alpha{alpha}\"\n",
    "\n",
    "path = ckpt_dir + f\"/{run_name}_history.csv\"\n",
    "hist_df = pd.read_csv(path)\n",
    "print(hist_df.head())\n",
    "hist_df.plot(x=\"epoch\", y=[\"train_loss\", \"val_loss\"], logy=True, grid=True, title=run_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d93735",
   "metadata": {},
   "outputs": [],
   "source": [
    "R_best = 0\n",
    "best_val = math.inf\n",
    "\n",
    "val_hist_R = []\n",
    "learning_hist_R = []\n",
    "\n",
    "for R in R_list:\n",
    "    if kernel_regime == \"exp\":\n",
    "        run_name = f\"loc_window_kernel_{R}_\" + data_regime + '_' + kernel_regime + f\"_xi{xi}\"\n",
    "    elif kernel_regime == \"yukawa\":\n",
    "        run_name = f\"loc_window_kernel_{R}_\" + data_regime + '_' + kernel_regime + f\"_lam{lam}\"\n",
    "    elif kernel_regime == \"power\":\n",
    "        run_name = f\"loc_window_kernel_{R}_\" + data_regime + '_' + kernel_regime + f\"_alpha{alpha}\"\n",
    "\n",
    "    model, normalization, epoch, val_loss = load_checkpoint(ckpt_dir + f\"/{run_name}_best.pt\", KernelOnlyEnergyNN, device=device)\n",
    "\n",
    "    val_hist_R.append((R, val_loss))\n",
    "    learning_hist_R.append((R, ))\n",
    "\n",
    "    print(f\"Model {run_name}: best val loss = {val_loss:.6f} at epoch {epoch}\")\n",
    "    if val_loss < best_val:\n",
    "        best_val = val_loss\n",
    "        R_best = R\n",
    "\n",
    "    print(f\"Best model: R={R_best}, val_loss={best_val:.6f}\")\n",
    "\n",
    "print(\"Validation history:\")\n",
    "for R, val_loss in val_hist_R:\n",
    "    print(f\"R={R}: val_loss={val_loss:.6f}\")\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot([x[0] for x in val_hist_R], [x[1] for x in val_hist_R], 'o-', label='Best validation error', linewidth=2)\n",
    "plt.axhline(0, color='k', linewidth=0.5)\n",
    "plt.xlabel(\"R (kernel range)\")\n",
    "plt.ylabel(\"learning error\")\n",
    "# plt.ylim((0.0, 1e-4))\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "if kernel_regime == \"exp\":\n",
    "    plt.title(f\"Local kernel learning ({data_regime}, exp, xi={xi})\")\n",
    "elif kernel_regime == \"yukawa\":\n",
    "    plt.title(f\"Local kernel learning ({data_regime}, yukawa, lam={lam})\")\n",
    "elif kernel_regime == \"power\":\n",
    "    plt.title(f\"Local kernel learning ({data_regime}, power, alpha={alpha})\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# For saving data used in Figure 2\n",
    "# data = np.column_stack([[x[0] for x in val_hist_R], [x[1] for x in val_hist_R]])\n",
    "# np.savetxt(f\"Figure_2/hist_loc_kernel_xi{xi}.txt\", data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa4e9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "R = 30\n",
    "if kernel_regime == \"exp\":\n",
    "    run_name = f\"loc_window_kernel_{R}_\" + data_regime + '_' + kernel_regime + f\"_xi{xi}\"\n",
    "elif kernel_regime == \"yukawa\":\n",
    "    run_name = f\"loc_window_kernel_{R}_\" + data_regime + '_' + kernel_regime + f\"_lam{lam}\"\n",
    "elif kernel_regime == \"power\":\n",
    "    run_name = f\"loc_window_kernel_{R}_\" + data_regime + '_' + kernel_regime + f\"_alpha{alpha}\"\n",
    "model, normalization, epoch, val_loss = load_checkpoint(ckpt_dir + f\"/{run_name}_best.pt\", KernelOnlyEnergyNN, device=device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    k_full = model.kernel_conv.build_kernel().view(-1).cpu().numpy() \n",
    "\n",
    "r_grid = np.arange(-R, R+1)\n",
    "\n",
    "if kernel_regime == \"exp\":\n",
    "    def K_true(r):\n",
    "        return np.exp(-np.abs(r) / xi)\n",
    "elif kernel_regime == \"yukawa\":\n",
    "    def K_true(r):\n",
    "        r_abs = np.abs(r)\n",
    "        out = np.exp(-r_abs / lam) / np.maximum(r_abs, 1.0)\n",
    "        return out * (r_abs > 0)\n",
    "elif kernel_regime == \"power\":\n",
    "    def K_true(r):\n",
    "        r_abs = np.abs(r)\n",
    "        out = 1.0 / (np.maximum(r_abs, 1.0)**alpha)\n",
    "        return out * (r_abs > 0)    \n",
    "\n",
    "k_true = K_true(r_grid)\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(r_grid, k_full , 'o-', label='Learned kernel (window)', linewidth=2)\n",
    "plt.plot(r_grid, k_true, 's--', label='True kernel', alpha=0.7)\n",
    "plt.axhline(0, color='k', linewidth=0.5)\n",
    "plt.xlabel(\"r = i - j\")\n",
    "plt.ylabel(\"K_r\")\n",
    "plt.xlim(-R, R)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "if kernel_regime == \"exp\":\n",
    "    plt.title(f\"Local kernel learning ({data_regime}, R={R}, exp, xi={xi})\")\n",
    "elif kernel_regime == \"yukawa\":\n",
    "    plt.title(f\"Local kernel learning ({data_regime}, R={R}, yukawa, lam={lam})\")\n",
    "elif kernel_regime == \"power\":\n",
    "    plt.title(f\"Local kernel learning ({data_regime}, R={R}, power, alpha={alpha})\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# For saving data used in Figure 2\n",
    "# data = np.column_stack([r_grid, k_full])\n",
    "# np.savetxt(f\"Figure_2/loc_kernel_xi{xi}.txt\", data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
