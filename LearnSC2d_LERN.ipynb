{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5feb370",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import numpy as np\n",
    "import math, os, time, copy\n",
    "import torch.fft as tfft\n",
    "import pandas as pd\n",
    "import torch_dct as dct\n",
    "from numpy import size\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from ewaldnn2d import *\n",
    "\n",
    "torch.random.manual_seed(1234) # for reproducibility\n",
    "\n",
    "# Global settings\n",
    "dtype = torch.float64\n",
    "device = \"cpu\"\n",
    "N_batch = 100\n",
    "N_epochs = 10000\n",
    "lr = 1e-1 # we will use a LR scheduler, so this is just an initial value\n",
    "min_delta = 1e-5 # min change in the monitored quantity to qualify as an improvement\n",
    "patience = 100    # epochs to wait for improvement before stopping training'\n",
    "pad_mode = \"reflect\" # in this example, we use reflective padding for local feature generation\n",
    "N_pow = 1 # number of local features per grid point\n",
    "N_train = 1500\n",
    "N_test = 250\n",
    "N_val = 250\n",
    "N_energy_terms = 1 # number of energy terms for the LERN model\n",
    "\n",
    "# grid and basis settings\n",
    "N_x = 32 # number of grid points in x direction\n",
    "N_y = N_x # number of grid points in y direction\n",
    "m_x = torch.arange(0, N_x, dtype=dtype, device=device)             # (N_x,)\n",
    "m_y = torch.arange(0, N_y, dtype=dtype, device=device)             # (N_y,)\n",
    "abs_val = torch.sqrt(m_x[:, None]**2 + m_y[None, :]**2)  # (M_x, M_y)\n",
    "x = torch.linspace(0, 1, N_x, dtype=dtype, device=device)            # (N_x,)\n",
    "y = torch.linspace(0, 1, N_y, dtype=dtype, device=device)            # (N_y,)\n",
    "DM_x = torch.cos(torch.pi * torch.outer(m_x, x))                  # (M_x, N_x)\n",
    "DM_y = torch.cos(torch.pi * torch.outer(m_y, y))                  # (M_y, N_y)\n",
    "DerDM_x = -torch.pi * m_x[:, None] * torch.sin(torch.pi * torch.outer(m_x, x))  # (M_x, N_x) # derivative of design matrix\n",
    "DerDM_y = -torch.pi * m_y[:, None] * torch.sin(torch.pi * torch.outer(m_y, y))  # (M_y, N_y) # derivative of design matrix\n",
    "\n",
    "data_regime = \"rough\" # \"smooth\" or \"rough\"\n",
    "if data_regime == \"smooth\":\n",
    "    M_cutoff = 10 # maximum harmonic   \n",
    "    std_harm = 2.0 / (1.0 + 0.2 * abs_val)**2 * (abs_val <= M_cutoff).double()  # (M_x, M_y)\n",
    "elif data_regime == \"rough\":\n",
    "    std_harm = 2.0 / (1.0 + 0.0 * abs_val)**2 # (M_x, M_y)\n",
    "else:\n",
    "    raise ValueError(\"regime must be 'smooth' or 'rough'\")\n",
    "std_harm[0, 0] = 0.0 # no uniform density offset\n",
    "\n",
    "# interaction kernel parameters\n",
    "qs = 0.5 # screening momentum\n",
    "amp = 1.0 # amplitude of interaction kernel\n",
    "kernel_regime = \"screened_coulomb\"\n",
    "\n",
    "# unscreened Hartree-Fock total energy function\n",
    "def E_HF(rho: torch.Tensor, d_rho_x: torch.Tensor, d_rho_y: torch.Tensor, eng_dens_flag: bool = False) -> torch.Tensor:\n",
    "        return amp * E_int_ms_dct(rho, kernel=kernel_regime, eng_dens_flag=eng_dens_flag, qs=0.0)\n",
    "\n",
    "# screened total energy function\n",
    "def E_SC(rho: torch.Tensor, d_rho_x: torch.Tensor, d_rho_y: torch.Tensor, eng_dens_flag: bool = False) -> torch.Tensor:\n",
    "        return amp * E_int_ms_dct(rho, kernel=kernel_regime, eng_dens_flag=eng_dens_flag, qs=qs)\n",
    "    \n",
    "# generate train/test split\n",
    "flag_generate_data = True # if True, generate new data; if False, load existing data from disk\n",
    "if flag_generate_data:\n",
    "    N_batch_int = 10 # number of density profiles per data generation batch\n",
    "    torch.manual_seed(1234) # for reproducibility\n",
    "    rho_train, d_rho_x_train, d_rho_y_train, a_train, E_HF_train, E_loc_SC_train = generate_SC_data_2d(N_train, N_batch_int, E_HF, E_SC, std_harm=std_harm, DM_x=DM_x, DerDM_x=DerDM_x, DM_y=DM_y, DerDM_y=DerDM_y)\n",
    "    rho_test, d_rho_x_test, d_rho_y_test, a_test, E_HF_test, E_loc_SC_test = generate_SC_data_2d(N_test, N_batch_int, E_HF, E_SC, std_harm=std_harm, DM_x=DM_x, DerDM_x=DerDM_x, DM_y=DM_y, DerDM_y=DerDM_y) \n",
    "    rho_val, d_rho_x_val, d_rho_y_val, a_val, E_HF_val, E_loc_SC_val = generate_SC_data_2d(N_val, N_batch_int, E_HF, E_SC, std_harm=std_harm, DM_x=DM_x, DerDM_x=DerDM_x, DM_y=DM_y, DerDM_y=DerDM_y)  \n",
    "    # save data to disk\n",
    "    os.makedirs(\"DATA2d\", exist_ok=True)\n",
    "\n",
    "    fname = f\"DATA2d/LERN_dataset_{data_regime}_{kernel_regime}_{qs}_{amp}_{N_x}_{N_y}.pt\"\n",
    "\n",
    "    torch.save(\n",
    "        {\n",
    "            \"rho_train\": rho_train,\n",
    "            \"d_rho_x_train\": d_rho_x_train,\n",
    "            \"d_rho_y_train\": d_rho_y_train,\n",
    "            \"a_train\": a_train,\n",
    "            \"E_HF_train\": E_HF_train,\n",
    "            \"E_loc_SC_train\": E_loc_SC_train,\n",
    "            \"rho_val\": rho_val,\n",
    "            \"d_rho_x_val\": d_rho_x_val,\n",
    "            \"d_rho_y_val\": d_rho_y_val,\n",
    "            \"a_val\": a_val,\n",
    "            \"E_HF_val\": E_HF_val,\n",
    "            \"E_loc_SC_val\": E_loc_SC_val,\n",
    "            \"rho_test\": rho_test,\n",
    "            \"d_rho_x_test\": d_rho_x_test,\n",
    "            \"d_rho_y_test\": d_rho_y_test,\n",
    "            \"a_test\": a_test,\n",
    "            \"E_HF_test\": E_HF_test,\n",
    "            \"E_loc_SC_test\": E_loc_SC_test,\n",
    "            \"data_regime\": data_regime,\n",
    "            \"kernel_regime\": kernel_regime,\n",
    "        },\n",
    "        fname,\n",
    "    )\n",
    "else:\n",
    "    data = torch.load(f\"DATA2d/LERN_dataset_{data_regime}_{kernel_regime}_{qs}_{amp}_{N_x}_{N_y}.pt\")\n",
    "    rho_train = data[\"rho_train\"]\n",
    "    E_HF_train = data[\"E_HF_train\"]\n",
    "    E_loc_SC_train = data[\"E_loc_SC_train\"]\n",
    "    rho_test = data[\"rho_test\"]\n",
    "    E_HF_test = data[\"E_HF_test\"]\n",
    "    E_loc_SC_test = data[\"E_loc_SC_test\"]\n",
    "    rho_val = data[\"rho_val\"]\n",
    "    E_HF_val = data[\"E_HF_val\"]\n",
    "    E_loc_SC_val = data[\"E_loc_SC_val\"]\n",
    "\n",
    "features_train = generate_loc_features_rs(rho_train, N_pow=N_pow)  # (N_train, N_x, N_y, N_pow)\n",
    "features_test  = generate_loc_features_rs(rho_test, N_pow=N_pow)   # (N_test, N_x, N_y, N_pow)\n",
    "features_val   = generate_loc_features_rs(rho_val, N_pow=N_pow)    # (N_val, N_x, N_y, N_pow)\n",
    "\n",
    "# Extend features with neighbor information\n",
    "R_feat = 1.0 # radius for neighbor feature extension\n",
    "features_train = extend_features_neighbors_2d(features_train, R=R_feat)\n",
    "features_test  = extend_features_neighbors_2d(features_test, R=R_feat)\n",
    "features_val   = extend_features_neighbors_2d(features_val, R=R_feat)\n",
    "\n",
    "# Normalize features\n",
    "mean_feat, std_feat = compute_normalization_stats(features_train)\n",
    "features_train_norm = normalize_features(features_train, mean_feat, std_feat)\n",
    "features_test_norm = normalize_features(features_test, mean_feat, std_feat)\n",
    "features_val_norm = normalize_features(features_val, mean_feat, std_feat)\n",
    "\n",
    "# Supplement the features with the unnormalized SC energy term (for the LERN model)\n",
    "features_train_norm = torch.cat([features_train_norm, E_loc_SC_train], dim=-1)  # (N_train, N_x, N_y, N_feat + 1)\n",
    "features_test_norm  = torch.cat([features_test_norm,  E_loc_SC_test], dim=-1)   # (N_test,  N_x, N_y, N_feat + 1)\n",
    "features_val_norm   = torch.cat([features_val_norm,   E_loc_SC_val], dim=-1)    # (N_val,   N_x, N_y, N_feat + 1)\n",
    "\n",
    "# Normalize targets\n",
    "E_mean = E_HF_train.mean()\n",
    "E_std = E_HF_train.std()\n",
    "E_HF_train_norm = (E_HF_train - E_mean) / E_std\n",
    "E_HF_test_norm = (E_HF_test - E_mean) / E_std\n",
    "E_HF_val_norm = (E_HF_val - E_mean) / E_std\n",
    "\n",
    "# Datasets\n",
    "train_dataset = TensorDataset(features_train_norm, E_HF_train_norm)\n",
    "val_dataset   = TensorDataset(features_val_norm,   E_HF_val_norm)\n",
    "test_dataset  = TensorDataset(features_test_norm,  E_HF_test_norm)\n",
    "\n",
    "# Loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=N_batch, shuffle=True,  drop_last=False)\n",
    "val_loader   = DataLoader(val_dataset,   batch_size=N_batch, shuffle=False, drop_last=False)\n",
    "test_loader  = DataLoader(test_dataset,  batch_size=N_batch, shuffle=False, drop_last=False)\n",
    "\n",
    "_, _, _, N_feat = features_train.shape\n",
    "print(f\"Number of local features per grid point: {N_feat}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02195293",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_dir = \"LearningSC2d_checkpoints\"\n",
    "flag_train = True  # set to True to train models\n",
    "learning_regime = \"LERN2d\"\n",
    "\n",
    "n_hidden_list = [1, 2, 3, 4]\n",
    "n_neurons_list = [8, 16, 32, 64]\n",
    "\n",
    "if flag_train:\n",
    "    for n_hidden in n_hidden_list:\n",
    "        for n_neurons in n_neurons_list:\n",
    "\n",
    "            run_name = f\"LERN2d_\" + data_regime + '_' + kernel_regime + f\"_{qs}_{amp}_{N_x}_{N_y}_{N_feat}_{N_energy_terms}_{n_hidden}_{n_neurons}\"\n",
    "\n",
    "            torch.manual_seed(1234) # for reproducibility    \n",
    "            model = LERN2d(\n",
    "                    N_x=N_x,\n",
    "                    N_y=N_y,\n",
    "                    N_energy_terms=N_energy_terms,\n",
    "                    N_feat=N_feat,\n",
    "                    n_hidden=n_hidden,\n",
    "                    n_neurons=n_neurons,\n",
    "                    mean_feat=mean_feat,\n",
    "                    std_feat=std_feat,\n",
    "                    E_mean=E_mean,\n",
    "                    E_std=E_std,\n",
    "                ).to(device=device, dtype=dtype)\n",
    "\n",
    "            optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "            criterion = nn.MSELoss()\n",
    "\n",
    "            # Reduce LR when val loss plateaus\n",
    "            scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "                optimizer, mode='min', factor=0.5, patience=50, cooldown=2, min_lr=1e-6\n",
    "            )\n",
    "\n",
    "            hist, best_epoch = train_with_early_stopping(\n",
    "                model=model,\n",
    "                train_loader=train_loader,\n",
    "                val_loader=val_loader,\n",
    "                criterion=criterion,\n",
    "                optimizer=optimizer,\n",
    "                scheduler=scheduler,\n",
    "                max_epochs=N_epochs,\n",
    "                patience=patience,\n",
    "                min_delta=min_delta,\n",
    "                ckpt_dir=ckpt_dir,\n",
    "                run_name=run_name,\n",
    "                learning_regime=learning_regime,\n",
    "                N_x=N_x,\n",
    "                N_y=N_y,\n",
    "                device=device,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8451d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden = 1\n",
    "n_neurons = 8\n",
    "\n",
    "run_name = f\"LERN2d_\" + data_regime + '_' + kernel_regime + f\"_{qs}_{amp}_{N_x}_{N_y}_{N_feat}_{N_energy_terms}_{n_hidden}_{n_neurons}\"\n",
    "\n",
    "path = ckpt_dir + f\"/{run_name}_history.csv\"\n",
    "hist_df = pd.read_csv(path)\n",
    "print(hist_df.head())\n",
    "hist_df.plot(x=\"epoch\", y=[\"train_loss\", \"val_loss\"], logy=True, grid=True, title=run_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b64fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, normalization, epoch, val_loss = load_checkpoint(\n",
    "        ckpt_dir + f\"/{run_name}_best.pt\",\n",
    "        LERN2d,\n",
    "        device=device\n",
    "    )\n",
    "model = model.to(device=device, dtype=dtype)\n",
    "\n",
    "k = 0  # index of the test sample to visualize\n",
    "features_example = features_test_norm[k:k+1, :, :, :N_feat]  # (1, N_x, N_y, N_feat)\n",
    "factors = model.local_nn(features_example)\n",
    "rho_example = rho_test[k:k+1, :, :]  # (1, N_x, N_y)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(5, 4))\n",
    "im = plt.imshow(\n",
    "    rho_example.numpy().squeeze().T,              # transpose so x is horizontal, y vertical\n",
    "    origin=\"lower\",\n",
    "    extent=[0, 1, 0, 1],   # x from 0 to 1, y from 0 to 1\n",
    "    aspect=\"equal\"\n",
    ")\n",
    "plt.colorbar(im, label=r\"$\\rho(x,y)$\")\n",
    "plt.xlabel(r\"$x$\")\n",
    "plt.ylabel(r\"$y$\")\n",
    "if data_regime == \"rough\":\n",
    "    plt.title(\"Sampled 2D density profile (rough)\")\n",
    "elif data_regime == \"smooth\":\n",
    "    plt.title(\"Sampled 2D density profile (smooth)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(5, 4))\n",
    "im = plt.imshow(\n",
    "    factors.detach().numpy().squeeze().T,              # transpose so x is horizontal, y vertical\n",
    "    origin=\"lower\",\n",
    "    extent=[0, 1, 0, 1],   # x from 0 to 1, y from 0 to 1\n",
    "    aspect=\"equal\"\n",
    ")\n",
    "plt.colorbar(im, label=r\"$factors(x,y)$\")\n",
    "plt.xlabel(r\"$x$\")\n",
    "plt.ylabel(r\"$y$\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
